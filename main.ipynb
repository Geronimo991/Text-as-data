{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e68f435e-f6f3-41e3-90ea-4776551b12df",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac536d87-4071-4a60-adcf-3662e21a72ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    6344\n",
       "4    1420\n",
       "1     925\n",
       "3     785\n",
       "2     526\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "data = pd.read_csv(\"data/Reviews.csv\")\n",
    "\n",
    "np.random.seed(1)\n",
    "data = data.iloc[np.random.permutation(len(data))]\n",
    "\n",
    "# Subset 10000 samples\n",
    "data = data.iloc[:10000,]\n",
    "\n",
    "data['Score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c854ec5-b99f-4d35-9491-e97cdb9fa94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    4662\n",
       "Negative     870\n",
       "Neutral      468\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def label(row):\n",
    "    if row['Score'] == 1 or row['Score'] == 2:\n",
    "        return 'Negative'\n",
    "    if row['Score'] == 3:\n",
    "        return 'Neutral'\n",
    "    return 'Positive'\n",
    "\n",
    "data['Sentiment'] = data.apply(lambda row: label(row), axis=1)\n",
    "\n",
    "ns = data.shape[0]\n",
    "ntr = int(ns * 0.6)\n",
    "nval = int(ns * 0.2)\n",
    "nte = ns - ntr - nval\n",
    "\n",
    "data = data.loc[:, ['Id', 'Sentiment', 'Text']]\n",
    "\n",
    "data_tr = data.iloc[:ntr, :]\n",
    "data_val = data.iloc[ntr:ntr+nval, :]\n",
    "data_te = data.iloc[ntr+nval:, :]\n",
    "\n",
    "data_tr.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b9770cd-d8c7-4590-ac96-93cd4d2e8d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    1568\n",
       "Negative     269\n",
       "Neutral      163\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4371cd37-8a61-4700-bf65-162898b06883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    1534\n",
       "Negative     312\n",
       "Neutral      154\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_te.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8b7444-1617-4fe9-9df0-8be19c662d78",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c3d1e2-c74f-4810-83e9-a63a69654f52",
   "metadata": {},
   "source": [
    "## Vectorise text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3117bad-374a-48ad-b9fd-d9f370348e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "# create TF-IDF vectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# fit vectorizer on text data\n",
    "tfidf.fit(data['Text'])\n",
    "\n",
    "# transform text data into TF-IDF vectors\n",
    "X = tfidf.transform(data['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9a89acf-99df-4b14-b1ff-53191f8b7238",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = X[:ntr, :]\n",
    "X_val = X[ntr:ntr+nval, :]\n",
    "X_te = X[ntr+nval:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f434d77-e4ef-49bc-9161-9eb4613ad87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = tfidf.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d8ed5bc-3785-4307-9e66-85c02a6e172c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeans:\n",
    "    def __init__(self, n_clusters=8, max_iter=300):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.centroids = X[np.random.choice(X.shape[0], self.n_clusters, replace=False)]\n",
    "        for i in range(self.max_iter):\n",
    "            distances = np.sqrt(((X - self.centroids[:, np.newaxis])**2).sum(axis=2))\n",
    "            labels = np.argmin(distances, axis=0)\n",
    "            for j in range(self.n_clusters):\n",
    "                if np.any(labels == j):\n",
    "                    self.centroids[j] = X[labels == j].mean(axis=0)\n",
    "\n",
    "    def predict(self, X):\n",
    "        distances = np.sqrt(((X - self.centroids[:, np.newaxis])**2).sum(axis=2))\n",
    "        labels = np.argmin(distances, axis=0)\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a7075dd-8eb4-4216-ad4e-f8d452686665",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = X_tr.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0daf106a-205e-4bcb-a547-c9025b89f693",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_val.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "832df8e7-3709-4f80-a0e9-281f9599455e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_te = X_te.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28b6525b-67c0-435f-aa64-4782496d9837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some sample data\n",
    "# X = np.random.randn(100, 3)\n",
    "\n",
    "# Create a KMeans object and fit the data\n",
    "kmeans = KMeans(n_clusters=5, max_iter=10)\n",
    "kmeans.fit(X_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8be1959e-8187-4bfb-954e-3ddc71a15ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the cluster labels for the data\n",
    "labels = kmeans.predict(X_tr)\n",
    "\n",
    "# Plot the data with different colors for each cluster\n",
    "# plt.scatter(X[:, 0], X[:, 1], c=labels)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "928a4f4d-ed3e-4556-949a-4ea2deaefe10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"my girls absolutely loved this tuna. they were in heaven and couldn't get enough of this tasty treat. A bit pricey since I do have 4 cats and the pack went super fast giving each of them a treat\",\n",
       "       'I have pretty much tried them all. The dark chocolate and fruit mix are perfect. This should be considered a drug.....;)'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tr.iloc[labels==0,2].values[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cbe239eb-f9e0-4d3b-a133-52fa22f6cd9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['I love the Cherry Pie Lara bar.  Best and tasty bar for when my sugar is low.  I recomend this Bar for diabetics low sugar only, as the carbs are about 30 for the bar.',\n",
       "       'This was just the basic ingredients that i could have found at the local harris teeter, but this kit had everything i needed to get me started making sushi.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tr.iloc[labels==1,2].values[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a820e800-3642-4c44-9d3d-05f7de089bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Melitta Cafe COllection Blanc et Noir coffee has a very smooth, refined armoma you notice as soon as you open up the package. That same aroma translates well throughout the brewing process and remains once poured into your cup. Once you taste it, you will find that the flavor is bold yet smooth, it has a slightly dark, powerful flavor without any of the coarseness or bitterness. I went directly from one of those high-pressure coffee pod brewing systems to using the Melitta in a percolator, and it seems Melitta has helped me find my way back to a better cup of coffee.',\n",
       "       'Made this coffee with a percolator maybe that is the wrong method but it cannot compare in taste to my regular coffee.  Will not buy it again.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tr.iloc[labels==2,2].values[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1d1e9a1-9b92-48d3-8da2-e2975275d086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['UPDATE - 8/9/2010<br />A lot can happen in just a couple months, the last two cases of these I have ordered from Amazon have been horrible.  I\\'ve had whole artichoke leaves in several cans (not the small soft leaves near the heart, I\\'m talking the big tough artichoke leaves). Brown spots over many of the artichokes.  Very poor quality.<br /><br />I contacted Amazon both times, the first time they replaced the case and the quality was much better.  The second time I asked them for a refund because two times in a couple months is not acceptable. I also contacted Reese direcly who doubted me and asked me to \"prove it\" by sending them two cans at my expense. I told them I\\'d gladly send them all the cans at their expense, but they would not do that. My impression of Reese has changed very much and I will no longer buy their products.<br /><br />ORIGINAL REVIEW - I\\'ve tried just about every brand out there and Reese, by far, is the best!  I love that you can buy them already quartered, great for tossing into salads.<br /><br />They are always good quality, not too firm, not too soft. Consistent taste, never a bad one in any can. Best price on Amazon too, about $1 cheaper per can then my local grocery store.',\n",
       "       'Just be forewarned it is a bit \"moist.\"  Have plenty of papertowels/napkins around when eating it.<br /><br />However for vegan jerky, this has by far the best texture. You will be picking it out of your teeth for hours! And for me, that is a good thing!<br /><br />My fav is the BBQ flavor, however their other flavors are very tasty as well :-)'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tr.iloc[labels==3,2].values[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42538082-dc72-45b2-bda3-3478924081de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['The vendor is fast and dependable. The tea is simply the best way to relax and great tasting too. Highly recommend !!',\n",
       "       \"This is a good tasting tea at a great price. If you don't normally like raspberry flavor, this isn't really raspberry flavor, if that makes sense. No heavy flavor.\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tr.iloc[labels==4,2].values[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3ce832c9-63f9-4742-83cb-12935c8a98db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster: 0\n",
      "biscotti\n",
      "north\n",
      "lunchbag\n",
      "bahlsen\n",
      "others\n",
      "\n",
      "Cluster: 1\n",
      "grain\n",
      "vacation\n",
      "sulfites\n",
      "latch\n",
      "we\n",
      "\n",
      "Cluster: 2\n",
      "pecan\n",
      "white\n",
      "drinker\n",
      "coffee\n",
      "coffee\n",
      "\n",
      "Cluster: 3\n",
      "matcha\n",
      "juice\n",
      "grams\n",
      "you\n",
      "gingerbread\n",
      "\n",
      "Cluster: 4\n",
      "kombucha\n",
      "tea\n",
      "valerian\n",
      "tea\n",
      "chinese\n"
     ]
    }
   ],
   "source": [
    "for k in range(5):\n",
    "    print(\"\\nCluster: %d\" % k)\n",
    "    tfidf_matrix = X_tr[labels==k]\n",
    "\n",
    "    # calculate the magnitude of each vector\n",
    "    vector_magnitudes = np.linalg.norm(tfidf_matrix, axis=1)\n",
    "\n",
    "    # get the indices of the top 5 vectors with highest magnitude\n",
    "    top_indices = np.argsort(vector_magnitudes)[::-1][:5]\n",
    "\n",
    "    # get the TF-IDF vectors for the top 5 indices\n",
    "    top_vectors = [tfidf_matrix[i, :] for i in top_indices]\n",
    "\n",
    "    # convert each vector to a dictionary with feature names as keys\n",
    "    # and TF-IDF values as values\n",
    "    top_dicts = [{feature_names[j]: top_vectors[i][j] for j in range(len(feature_names))}\n",
    "                 for i in range(len(top_vectors))]\n",
    "\n",
    "    # sort the dictionaries in descending order of TF-IDF values\n",
    "    for d in top_dicts:\n",
    "        sorted_items = sorted(d.items(), key=lambda x: x[1], reverse=True)\n",
    "        print(sorted_items[:1][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5270cd5e-7adf-4cd2-84e7-5eee97ed4dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>199</td>\n",
       "      <td>101</td>\n",
       "      <td>1218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>421</td>\n",
       "      <td>207</td>\n",
       "      <td>2084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80</td>\n",
       "      <td>49</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>135</td>\n",
       "      <td>90</td>\n",
       "      <td>617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>21</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0  Negative  Neutral  Positive\n",
       "row_0                             \n",
       "0           199      101      1218\n",
       "1           421      207      2084\n",
       "2            80       49       407\n",
       "3           135       90       617\n",
       "4            35       21       336"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(labels, data_tr.Sentiment.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388a7864-693d-446e-a8d2-c04c77671843",
   "metadata": {},
   "source": [
    "# Q3: Comparing Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521404cf-c528-4b26-bcd7-0088c58ec1fc",
   "metadata": {},
   "source": [
    "### Model 1: Dummy Classifier with strategy=\"most_frequent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d1e79189-47c2-45cb-b4ce-e750c6da4a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tr['Sentiment'].value_counts()\n",
    "pred_model_1 = np.array(['Positive']*data_val.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec2dee8-c7ad-40a6-85cc-61f4ad392c2f",
   "metadata": {},
   "source": [
    "### Model 2: Dummy Classifier with strategy=\"stratified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1d147208-cda3-42e1-ada6-d16ff5fcb668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Create and fit the DummyClassifier with strategy=\"stratified\"\n",
    "dummy = DummyClassifier(strategy=\"stratified\", random_state=42)\n",
    "dummy.fit(X_tr, data_tr['Sentiment'].values)\n",
    "\n",
    "pred_model_2 = dummy.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fec5752-9ea0-4518-9b7d-cb143087e8c7",
   "metadata": {},
   "source": [
    "### Model 3: LogisticRegression with One-hot vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cf0d36eb-b535-4901-b320-1ffdc77f2935",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Example data\n",
    "X_train = ['This is a positive review', \n",
    "           'This is a negative review', \n",
    "           'This is a neutral review']\n",
    "y_train = ['positive', 'negative', 'neutral']\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('classifier', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ca2f2b3e-d432-40bb-9dbe-02104d41d88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda\\envs\\tf2\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer()),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer()),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vectorizer', CountVectorizer()),\n",
       "                ('classifier', LogisticRegression())])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "pipeline.fit(data_tr['Text'].values, data_tr['Sentiment'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e747633f-0fd1-4691-8d75-1d55803cf352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example predictions\n",
    "# X_test = ['This is a great product', 'This is a terrible product']\n",
    "pred_model_3 = pipeline.predict(data_val['Text'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac245b3-dfe6-4cad-8570-33fc47f8c619",
   "metadata": {},
   "source": [
    "### Model 4: LogisticRegression with TF-IDF vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2b07f91b-071a-4466-b27b-cf129e77d936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# create a logistic regression model\n",
    "lr = LogisticRegression(random_state=42)\n",
    "\n",
    "# fit the model to the training data\n",
    "lr.fit(X_tr, data_tr['Sentiment'].values)\n",
    "\n",
    "# predict the target variable for the testing data\n",
    "pred_model_4 = lr.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24a6aa7-4711-4679-aac1-a8148186a709",
   "metadata": {},
   "source": [
    "### Model 5: SVC Classifier with One-hot vectorization (SVM with RBF kernel, default settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "050907c1-a713-4b4e-be77-5d81e943c6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# create CountVectorizer object for one-hot encoding\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# create SVC object with RBF kernel and default hyperparameters\n",
    "clf = SVC(kernel='rbf')\n",
    "\n",
    "# create pipeline for one-hot encoding and classification\n",
    "pipe = Pipeline([('vect', vectorizer), ('clf', clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2e8c135e-3a92-4777-a711-090598672a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit pipeline on training data\n",
    "pipe.fit(data_tr['Text'].values, data_tr['Sentiment'].values)\n",
    "\n",
    "# predict on test data\n",
    "pred_model_5 = pipe.predict(data_val['Text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "829cacb5-e2ee-4498-9210-25b8437d1c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Model 1: Dummy Classifier with strategy=most_frequent\n",
      "Accuracy: 0.784\n",
      "Macro-averaged Precision: 0.261\n",
      "Macro-averaged Recall: 0.333\n",
      "Macro-averaged F1: 0.293\n",
      "\n",
      "\n",
      "Model 2: Dummy Classifier with strategy=stratified\n",
      "Accuracy: 0.633\n",
      "Macro-averaged Precision: 0.33\n",
      "Macro-averaged Recall: 0.328\n",
      "Macro-averaged F1: 0.329\n",
      "\n",
      "\n",
      "Model 3: LogisticRegression with One-hot vectorization\n",
      "Accuracy: 0.815\n",
      "Macro-averaged Precision: 0.58\n",
      "Macro-averaged Recall: 0.541\n",
      "Macro-averaged F1: 0.556\n",
      "\n",
      "\n",
      "Model 4: LogisticRegression with TF-IDF vectorization\n",
      "Accuracy: 0.822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda\\envs\\tf2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\software\\anaconda\\envs\\tf2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro-averaged Precision: 0.678\n",
      "Macro-averaged Recall: 0.447\n",
      "Macro-averaged F1: 0.464\n",
      "\n",
      "\n",
      "Model 5: SVC Classifier with One-hot vectorization (SVM with RBF kernel, default settings)\n",
      "Accuracy: 0.804\n",
      "Macro-averaged Precision: 0.536\n",
      "Macro-averaged Recall: 0.388\n",
      "Macro-averaged F1: 0.389\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "res = [pred_model_1, pred_model_2, pred_model_3, pred_model_4, pred_model_5]\n",
    "model_name = [\"Model 1: Dummy Classifier with strategy=most_frequent\", \n",
    "              \"Model 2: Dummy Classifier with strategy=stratified\", \n",
    "              \"Model 3: LogisticRegression with One-hot vectorization\", \n",
    "              \"Model 4: LogisticRegression with TF-IDF vectorization\", \n",
    "              \"Model 5: SVC Classifier with One-hot vectorization (SVM with RBF kernel, default settings)\"]\n",
    "for i in range(5):\n",
    "    print(\"\\n\")\n",
    "    print(model_name[i])\n",
    "    y_true = data_val['Sentiment'].values\n",
    "    y_pred = res[i]\n",
    "    # calculate accuracy\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(\"Accuracy:\", round(accuracy, 3))\n",
    "    # calculate macro-averaged precision, recall, and F1\n",
    "    precision = precision_score(y_true, y_pred, average=\"macro\")\n",
    "    recall = recall_score(y_true, y_pred, average=\"macro\")\n",
    "    f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    print(\"Macro-averaged Precision:\", round(precision, 3))\n",
    "    print(\"Macro-averaged Recall:\", round(recall, 3))\n",
    "    print(\"Macro-averaged F1:\", round(f1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "113e657f-9b1b-49ea-a523-4628b3ad1bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative      0.703     0.335     0.453       269\n",
      "     Neutral      0.500     0.018     0.036       163\n",
      "    Positive      0.831     0.989     0.903      1568\n",
      "\n",
      "    accuracy                          0.822      2000\n",
      "   macro avg      0.678     0.447     0.464      2000\n",
      "weighted avg      0.787     0.822     0.772      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = res[3]\n",
    "report = classification_report(y_true, y_pred, digits=3)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b8c76c24-203c-4094-aa11-0e76d264e2c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = ['Negative', 'Neutral', 'Positive']\n",
    "f1_scores = [0.453, 0.036, 0.903]\n",
    "\n",
    "plt.bar(labels, f1_scores)\n",
    "plt.title('F1-scores for Sentiment Labels')\n",
    "plt.xlabel('Sentiment Label')\n",
    "plt.ylabel('F1-score')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c17cdf0-70e3-4eb7-bfdf-41465a405f2e",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "627769ef-d405-49fb-9372-00218c0a2a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "e17e5ea8-8020-4b4a-903a-13cc0d38c8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_tr, data_tr['Sentiment'].values)\n",
    "# Use the classifier to predict labels for the test set\n",
    "y_pred_dt = clf.predict(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "3956c1fa-7c89-4f2d-adae-202a40c25924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.654\n",
      "Macro-averaged Precision: 0.324\n",
      "Macro-averaged Recall: 0.326\n",
      "Macro-averaged F1: 0.324\n"
     ]
    }
   ],
   "source": [
    "y_true = data_val['Sentiment'].values\n",
    "y_pred = y_pred_dt\n",
    "\n",
    "# calculate accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(\"Accuracy:\", round(accuracy, 3))\n",
    "\n",
    "# calculate macro-averaged precision, recall, and F1\n",
    "precision = precision_score(y_true, y_pred, average=\"macro\")\n",
    "recall = recall_score(y_true, y_pred, average=\"macro\")\n",
    "f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "print(\"Macro-averaged Precision:\", round(precision, 3))\n",
    "print(\"Macro-averaged Recall:\", round(recall, 3))\n",
    "print(\"Macro-averaged F1:\", round(f1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8e4d30-9d4f-4355-bcdc-380af2a62a4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17405ebe-dec1-44a6-be8c-5e342afed93a",
   "metadata": {},
   "source": [
    "# Q4: Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "bc03b6d4-9ea8-47bd-8674-cd66005c8010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# create instance of TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# fit the vectorizer on training data\n",
    "tfidf_vectorizer.fit(data_tr['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "107b0e9e-4557-4c65-b9a9-c05bbbfc4d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform training and test data\n",
    "X_train_tfidf = tfidf_vectorizer.transform(data_tr['Text'])\n",
    "X_val_tfidf = tfidf_vectorizer.transform(data_val['Text'])\n",
    "X_te_tfidf = tfidf_vectorizer.transform(data_te['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "c7ac02aa-3635-4a8a-8616-038569c06851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create instance of LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "\n",
    "# fit the model on training data\n",
    "clf.fit(X_train_tfidf, data_tr['Sentiment'].values)\n",
    "\n",
    "# predict on test data\n",
    "y_pred = clf.predict(X_val_tfidf)\n",
    "\n",
    "# evaluate performance\n",
    "accuracy = accuracy_score(data_val['Sentiment'].values, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4a596b-d1cd-4a26-af02-923a3824c30b",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "124f4be8-a0d4-4fa5-9e69-b25c05c2b74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Define the range of C values to search over\n",
    "param_grid = {'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "f3b59992-5b34-4c4f-b822-4df74c230cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid['logisticregression__C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "0b51bbcb-8ca6-4a19-8c9f-b16c33683f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param: 0.001; Accuracy: 0.784\n",
      "Macro-averaged Precision: 0.261\n",
      "Macro-averaged Recall: 0.333\n",
      "Macro-averaged F1: 0.293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda\\envs\\tf2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param: 0.01; Accuracy: 0.784\n",
      "Macro-averaged Precision: 0.261\n",
      "Macro-averaged Recall: 0.333\n",
      "Macro-averaged F1: 0.293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda\\envs\\tf2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param: 0.1; Accuracy: 0.7845\n",
      "Macro-averaged Precision: 0.595\n",
      "Macro-averaged Recall: 0.335\n",
      "Macro-averaged F1: 0.296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda\\envs\\tf2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param: 1; Accuracy: 0.823\n",
      "Macro-averaged Precision: 0.701\n",
      "Macro-averaged Recall: 0.455\n",
      "Macro-averaged F1: 0.473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda\\envs\\tf2\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param: 10; Accuracy: 0.836\n",
      "Macro-averaged Precision: 0.644\n",
      "Macro-averaged Recall: 0.538\n",
      "Macro-averaged F1: 0.564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda\\envs\\tf2\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param: 100; Accuracy: 0.8255\n",
      "Macro-averaged Precision: 0.602\n",
      "Macro-averaged Recall: 0.547\n",
      "Macro-averaged F1: 0.565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda\\envs\\tf2\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param: 1000; Accuracy: 0.82\n",
      "Macro-averaged Precision: 0.595\n",
      "Macro-averaged Recall: 0.551\n",
      "Macro-averaged F1: 0.566\n",
      "param: 10000; Accuracy: 0.8205\n",
      "Macro-averaged Precision: 0.599\n",
      "Macro-averaged Recall: 0.555\n",
      "Macro-averaged F1: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda\\envs\\tf2\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(param_grid['logisticregression__C'])):\n",
    "    param = param_grid['logisticregression__C'][i]\n",
    "    \n",
    "    # create instance of LogisticRegression\n",
    "    clf = LogisticRegression(C=param)\n",
    "\n",
    "    # fit the model on training data\n",
    "    clf.fit(X_train_tfidf, data_tr['Sentiment'].values)\n",
    "\n",
    "    # predict on test data\n",
    "    y_pred = clf.predict(X_val_tfidf)\n",
    "\n",
    "    # evaluate performance\n",
    "    accuracy = accuracy_score(data_val['Sentiment'].values, y_pred)\n",
    "    print(f\"param: {param}; Accuracy: {accuracy}\")\n",
    "    \n",
    "    y_true = data_val['Sentiment'].values\n",
    "\n",
    "    # calculate accuracy\n",
    "\n",
    "    # calculate macro-averaged precision, recall, and F1\n",
    "    precision = precision_score(y_true, y_pred, average=\"macro\")\n",
    "    recall = recall_score(y_true, y_pred, average=\"macro\")\n",
    "    f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    \n",
    "    print(\"Macro-averaged Precision:\", round(precision, 3))\n",
    "    print(\"Macro-averaged Recall:\", round(recall, 3))\n",
    "    print(\"Macro-averaged F1:\", round(f1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f15a142-8fb9-484a-9fe2-1108fd7991f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "b7f31b14-169f-4da6-b30f-141bd07d0649",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda\\envs\\tf2\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sublinear_tf: True; max_features: None; Accuracy: 0.8345\n",
      "Macro-averaged Precision: 0.632\n",
      "Macro-averaged Recall: 0.53\n",
      "Macro-averaged F1: 0.554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda\\envs\\tf2\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sublinear_tf: True; max_features: 1000; Accuracy: 0.813\n",
      "Macro-averaged Precision: 0.589\n",
      "Macro-averaged Recall: 0.541\n",
      "Macro-averaged F1: 0.557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda\\envs\\tf2\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sublinear_tf: True; max_features: 10000; Accuracy: 0.833\n",
      "Macro-averaged Precision: 0.629\n",
      "Macro-averaged Recall: 0.527\n",
      "Macro-averaged F1: 0.551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda\\envs\\tf2\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sublinear_tf: True; max_features: 50000; Accuracy: 0.8345\n",
      "Macro-averaged Precision: 0.632\n",
      "Macro-averaged Recall: 0.53\n",
      "Macro-averaged F1: 0.554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda\\envs\\tf2\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sublinear_tf: False; max_features: None; Accuracy: 0.836\n",
      "Macro-averaged Precision: 0.644\n",
      "Macro-averaged Recall: 0.538\n",
      "Macro-averaged F1: 0.564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda\\envs\\tf2\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sublinear_tf: False; max_features: 1000; Accuracy: 0.8095\n",
      "Macro-averaged Precision: 0.584\n",
      "Macro-averaged Recall: 0.532\n",
      "Macro-averaged F1: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda\\envs\\tf2\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sublinear_tf: False; max_features: 10000; Accuracy: 0.8345\n",
      "Macro-averaged Precision: 0.636\n",
      "Macro-averaged Recall: 0.536\n",
      "Macro-averaged F1: 0.563\n",
      "sublinear_tf: False; max_features: 50000; Accuracy: 0.836\n",
      "Macro-averaged Precision: 0.644\n",
      "Macro-averaged Recall: 0.538\n",
      "Macro-averaged F1: 0.564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda\\envs\\tf2\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "for sublinear_tf in [True, False]:\n",
    "    for max_features in [None, 1000, 10000, 50000]:\n",
    "        # transform training and test data\n",
    "        tfidf_vectorizer = TfidfVectorizer(sublinear_tf=sublinear_tf, \n",
    "                                           max_features=max_features)\n",
    "        tfidf_vectorizer.fit(data_tr['Text'])\n",
    "        X_train_tfidf = tfidf_vectorizer.transform(data_tr['Text'])\n",
    "        X_val_tfidf = tfidf_vectorizer.transform(data_val['Text'])\n",
    "        X_te_tfidf = tfidf_vectorizer.transform(data_te['Text'])\n",
    "\n",
    "        # create instance of LogisticRegression\n",
    "        clf = LogisticRegression(C=10)\n",
    "\n",
    "        # fit the model on training data\n",
    "        clf.fit(X_train_tfidf, data_tr['Sentiment'].values)\n",
    "\n",
    "        # predict on test data\n",
    "        y_pred = clf.predict(X_val_tfidf)\n",
    "\n",
    "        # evaluate performance\n",
    "        accuracy = accuracy_score(data_val['Sentiment'].values, y_pred)\n",
    "        print(f\"sublinear_tf: {sublinear_tf}; max_features: {max_features}; Accuracy: {accuracy}\")\n",
    "\n",
    "        y_true = data_val['Sentiment'].values\n",
    "\n",
    "        # calculate macro-averaged precision, recall, and F1\n",
    "        precision = precision_score(y_true, y_pred, average=\"macro\")\n",
    "        recall = recall_score(y_true, y_pred, average=\"macro\")\n",
    "        f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "\n",
    "        print(\"Macro-averaged Precision:\", round(precision, 3))\n",
    "        print(\"Macro-averaged Recall:\", round(recall, 3))\n",
    "        print(\"Macro-averaged F1:\", round(f1, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81139a72-d94c-45c2-9689-9b474961da57",
   "metadata": {},
   "source": [
    "# Q5 Context vectors using BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8666bb18-09aa-4a20-bade-bb39dbd03bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67e25acd-5836-4d80-afb5-c8044d35b041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.03200030326843262,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 51,
       "postfix": null,
       "prefix": "Downloading pytorch_model.bin",
       "rate": null,
       "total": 501200538,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c991b3934474469bcce7904494d62ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/478M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Load the RoBERTa tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
    "model = AutoModel.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5aa1cf5-af21-4abc-ac13-5e31e24f92d9",
   "metadata": {},
   "source": [
    "## limit number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea537631-6d20-4811-94ee-e1e74911554a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syx\\AppData\\Local\\Temp/ipykernel_14812/795350021.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_tr['Text'] = data_tr['Text'].apply(limit_words)\n"
     ]
    }
   ],
   "source": [
    "# define a lambda function to limit the number of words in a text\n",
    "limit_words = lambda text: ' '.join(text.split()[:200])\n",
    "\n",
    "# apply the lambda function to the \"Text\" column of the dataframe\n",
    "data_tr['Text'] = data_tr['Text'].apply(limit_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "768447c9-bd6d-42fc-b10e-16b47ac62fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syx\\AppData\\Local\\Temp/ipykernel_14812/620808560.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_val['Text'] = data_val['Text'].apply(limit_words)\n"
     ]
    }
   ],
   "source": [
    "data_val['Text'] = data_val['Text'].apply(limit_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "87f1d69c-7104-4dbb-8dcc-1764d93b0e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syx\\AppData\\Local\\Temp/ipykernel_14812/1655369468.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_te['Text'] = data_te['Text'].apply(limit_words)\n"
     ]
    }
   ],
   "source": [
    "data_te['Text'] = data_te['Text'].apply(limit_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e25d9e6f-5517-4487-a6a3-138a9f29ceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_tr = np.zeros((data_tr.shape[0], 768))\n",
    "for i in range(data_tr.shape[0]):\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    feature_tr[i, :] = np.array(feature_extraction(data_tr.iloc[i, :]['Text'])[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784f25a0-0f32-4667-b43d-1a91d297fb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_val = np.zeros((data_val.shape[0], 768))\n",
    "\n",
    "for i in range(data_val.shape[0]):\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    feature_val[i, :] = np.array(feature_extraction(data_val.iloc[i, :]['Text'])[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f18f43b-e268-44f7-ad37-a1c6e5b6ac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_te = np.zeros((data_te.shape[0], 768))\n",
    "\n",
    "for i in range(data_te.shape[0]):\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    feature_te[i, :] = np.array(feature_extraction(data_te.iloc[i, :]['Text'])[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ceaacc0c-f758-4b6d-a41b-0c197c5cdac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(\"feature_tr.txt\", feature_tr)\n",
    "# np.savetxt(\"feature_val.txt\", feature_val)\n",
    "# np.savetxt(\"feature_te.txt\", feature_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "94f6a736-95e5-4b11-9a35-d05661a403fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_tr = np.loadtxt(\"feature_tr.txt\")\n",
    "feature_val = np.loadtxt(\"feature_val.txt\")\n",
    "feature_te = np.loadtxt(\"feature_te.txt\")\n",
    "# np.savetxt(\"feature_val.txt\", feature_val)\n",
    "# np.savetxt(\"feature_te.txt\", feature_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd1568d-c9f5-47f5-9e95-704e290fb3d5",
   "metadata": {},
   "source": [
    "## Part a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f622dc8f-d93a-4e78-8f02-e48700e08431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.849\n",
      "Macro-averaged Precision: 0.661\n",
      "Macro-averaged Recall: 0.553\n",
      "Macro-averaged F1: 0.562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda\\envs\\tf2\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# create a logistic regression model\n",
    "lr = LogisticRegression(random_state=42)\n",
    "\n",
    "# fit the model to the training data\n",
    "lr.fit(feature_tr, data_tr['Sentiment'].values)\n",
    "\n",
    "# predict the target variable for the testing data\n",
    "pred_lr = lr.predict(feature_val)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "y_true = data_val['Sentiment'].values\n",
    "y_pred = pred_lr\n",
    "\n",
    "# calculate accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(\"Accuracy:\", round(accuracy, 3))\n",
    "\n",
    "# calculate macro-averaged precision, recall, and F1\n",
    "precision = precision_score(y_true, y_pred, average=\"macro\")\n",
    "recall = recall_score(y_true, y_pred, average=\"macro\")\n",
    "f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "print(\"Macro-averaged Precision:\", round(precision, 3))\n",
    "print(\"Macro-averaged Recall:\", round(recall, 3))\n",
    "print(\"Macro-averaged F1:\", round(f1, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bf9e72-b13d-4771-bdbb-79d51860aefe",
   "metadata": {},
   "source": [
    "## part b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f84760f1-8cde-46fb-abca-63aa1d22ae1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbe40813-4512-447b-b32c-6d49476ab024",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tr = data_tr.reset_index()\n",
    "data_te = data_te.reset_index()\n",
    "data_val = data_val.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9618d90-30ed-4f78-ae94-4fe1dfe6ea33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# create a label encoder object\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(data_tr['Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "505a5965-7db6-418f-8a87-202f4728ef94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and transform the labels column to integers\n",
    "data_tr['label_int'] = label_encoder.transform(data_tr['Sentiment'])\n",
    "data_te['label_int'] = label_encoder.transform(data_te['Sentiment'])\n",
    "data_val['label_int'] = label_encoder.transform(data_val['Sentiment'])\n",
    "train_texts = data_tr['Text']\n",
    "train_labels = data_tr['label_int']\n",
    "val_texts = data_val['Text']\n",
    "val_labels = data_val['label_int']\n",
    "te_texts = data_te['Text']\n",
    "te_labels = data_te['label_int']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "804b1c5c-96d7-4b58-afba-54cba0998c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the Roberta tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffd3d4fd-4f7e-4fdd-a987-88950adf6dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Encode the train and validation texts using the tokenizer\n",
    "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True)\n",
    "val_encodings = tokenizer(list(val_texts), truncation=True, padding=True)\n",
    "te_encodings = tokenizer(list(te_texts), truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5418c1dc-bfe6-447a-92f5-363269b88dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the labels to a list of integers\n",
    "train_labels = list(train_labels)\n",
    "val_labels = list(val_labels)\n",
    "te_labels = list(te_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7fb1a993-086a-40a4-b866-1bc04b0db986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PyTorch dataset\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx], device='cpu') for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], device='cpu')\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f192bc16-70a6-4667-89ce-c593c81b5ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_encodings, train_labels)\n",
    "val_dataset = CustomDataset(val_encodings, val_labels)\n",
    "te_dataset = CustomDataset(te_encodings, te_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7094f8b3-439f-428e-ac4e-2729aa293773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Roberta model for sequence classification\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca43dac2-1759-49b3-a2d4-d9b40d482271",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162ed994-291a-489e-b832-c40e21b91e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=1,              # total number of training epochs\n",
    "    per_device_train_batch_size=4,  # batch size per device during training\n",
    "    per_device_eval_batch_size=4,   # batch size for evaluation\n",
    "    learning_rate=1e-4,              # learning rate\n",
    "    weight_decay=0,                  # weight decay\n",
    "    evaluation_strategy='epoch',     # evaluation strategy to adopt during training\n",
    "    disable_tqdm=False,              # disable tqdm progress bar\n",
    ")\n",
    "\n",
    "# Create a trainer instance and train the model\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,              # training arguments, defined above\n",
    "    train_dataset=train_dataset,     # training dataset\n",
    "    eval_dataset=val_dataset         # evaluation dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7acb287-818a-4789-8bd2-5e0205210645",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cbbe99-3abb-4c78-858b-bee36d571bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the validation set\n",
    "eval_results = trainer.evaluate(eval_dataset=val_dataset)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387d1473-051c-4979-aeb1-126520006740",
   "metadata": {},
   "source": [
    "# Q6 Conclusions and Future work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54dee18d-a14c-451a-9644-9843e47ebff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.856\n",
      "Macro-averaged Precision: 0.736\n",
      "Macro-averaged Recall: 0.561\n",
      "Macro-averaged F1: 0.576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda\\envs\\tf2\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# create a logistic regression model\n",
    "lr = LogisticRegression(random_state=42)\n",
    "\n",
    "# fit the model to the training data\n",
    "lr.fit(feature_tr, data_tr['Sentiment'].values)\n",
    "\n",
    "# predict the target variable for the testing data\n",
    "pred_lr = lr.predict(feature_te)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "y_true = data_te['Sentiment'].values\n",
    "y_pred = pred_lr\n",
    "\n",
    "# calculate accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(\"Accuracy:\", round(accuracy, 3))\n",
    "\n",
    "# calculate macro-averaged precision, recall, and F1\n",
    "precision = precision_score(y_true, y_pred, average=\"macro\")\n",
    "recall = recall_score(y_true, y_pred, average=\"macro\")\n",
    "f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "print(\"Macro-averaged Precision:\", round(precision, 3))\n",
    "print(\"Macro-averaged Recall:\", round(recall, 3))\n",
    "print(\"Macro-averaged F1:\", round(f1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "66b9cde0-da1e-4a56-8ef1-4d4893dc2ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 199    3  110]\n",
      " [  41   10  103]\n",
      " [  27    4 1503]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# create confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc639f19-d0d9-4ecb-bd5c-2a0098666b60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e19d7e-c7db-4107-8e1b-83afdaf89c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f286c79-29a5-4d82-b7bf-15c5db0128dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422e573d-db6e-4f48-9af4-c47b89352568",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
